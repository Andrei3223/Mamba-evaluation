{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\n\nfrom datasets import load_dataset\n# from trl import SFTTrainer\n# from peft import LoraConfig","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-11T21:49:44.143455Z","iopub.execute_input":"2024-04-11T21:49:44.143920Z","iopub.status.idle":"2024-04-11T21:49:47.247761Z","shell.execute_reply.started":"2024-04-11T21:49:44.143861Z","shell.execute_reply":"2024-04-11T21:49:47.246431Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q transformers==4.39","metadata":{"execution":{"iopub.status.busy":"2024-04-11T21:49:47.249213Z","iopub.execute_input":"2024-04-11T21:49:47.249753Z","iopub.status.idle":"2024-04-11T21:50:17.066350Z","shell.execute_reply.started":"2024-04-11T21:49:47.249718Z","shell.execute_reply":"2024-04-11T21:50:17.064452Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q git+https://github.com/huggingface/transformers@main\n!pip install -q causal-conv1d>=1.2.0\n!pip install -q mamba-ssm","metadata":{"execution":{"iopub.status.busy":"2024-04-11T21:50:17.069467Z","iopub.execute_input":"2024-04-11T21:50:17.070053Z","iopub.status.idle":"2024-04-11T21:51:22.603409Z","shell.execute_reply.started":"2024-04-11T21:50:17.070000Z","shell.execute_reply":"2024-04-11T21:51:22.601260Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[13 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m /tmp/pip-install-nh_mengz/causal-conv1d_d95e15bb4563446c90ced62fe399c627/setup.py:74: UserWarning: causal_conv1d was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n  \u001b[31m   \u001b[0m   warnings.warn(\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-nh_mengz/causal-conv1d_d95e15bb4563446c90ced62fe399c627/setup.py\", line 108, in <module>\n  \u001b[31m   \u001b[0m     if bare_metal_version >= Version(\"11.8\"):\n  \u001b[31m   \u001b[0m NameError: name 'bare_metal_version' is not defined\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m torch.__version__  = 2.1.2+cpu\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n  \n  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n  \u001b[31m╰─>\u001b[0m \u001b[31m[13 lines of output]\u001b[0m\n  \u001b[31m   \u001b[0m /tmp/pip-install-_29nw11h/mamba-ssm_7551f43c1da3470cbcb7c95c57064a09/setup.py:78: UserWarning: mamba_ssm was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, only images whose names contain 'devel' will provide nvcc.\n  \u001b[31m   \u001b[0m   warnings.warn(\n  \u001b[31m   \u001b[0m Traceback (most recent call last):\n  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-_29nw11h/mamba-ssm_7551f43c1da3470cbcb7c95c57064a09/setup.py\", line 112, in <module>\n  \u001b[31m   \u001b[0m     if bare_metal_version >= Version(\"11.8\"):\n  \u001b[31m   \u001b[0m NameError: name 'bare_metal_version' is not defined\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m torch.__version__  = 2.1.2+cpu\n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \n  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n  \n  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n\n\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n\u001b[31m╰─>\u001b[0m See above for output.\n\n\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n\u001b[1;36mhint\u001b[0m: See above for details.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -U -q accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-11T21:51:22.606460Z","iopub.execute_input":"2024-04-11T21:51:22.606968Z","iopub.status.idle":"2024-04-11T21:51:37.373509Z","shell.execute_reply.started":"2024-04-11T21:51:22.606926Z","shell.execute_reply":"2024-04-11T21:51:37.371571Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# !pip install -q nltk\n# !pip install -q twython\n# !pip install -q textblob\n# !pip install -q wordcloud\n# !pip install -q einops","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.406136Z","iopub.execute_input":"2024-04-09T19:56:24.406560Z","iopub.status.idle":"2024-04-09T19:56:24.413183Z","shell.execute_reply.started":"2024-04-09T19:56:24.406519Z","shell.execute_reply":"2024-04-09T19:56:24.411719Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Wiki text dataset","metadata":{}},{"cell_type":"code","source":"# from datasets import load_dataset\n# from sklearn.model_selection import train_test_split\n\n# dataset = load_dataset(\"wikipedia\", \"20220301.en\")","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.414670Z","iopub.execute_input":"2024-04-09T19:56:24.415121Z","iopub.status.idle":"2024-04-09T19:56:24.454056Z","shell.execute_reply.started":"2024-04-09T19:56:24.415080Z","shell.execute_reply":"2024-04-09T19:56:24.452891Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# data = dataset[\"train\"]\n\n# data.shape","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.456755Z","iopub.execute_input":"2024-04-09T19:56:24.457426Z","iopub.status.idle":"2024-04-09T19:56:24.464600Z","shell.execute_reply.started":"2024-04-09T19:56:24.457387Z","shell.execute_reply":"2024-04-09T19:56:24.463730Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# train, test = train_test_split(data, test_size=0.2, random_state=42)\n","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.465604Z","iopub.execute_input":"2024-04-09T19:56:24.465950Z","iopub.status.idle":"2024-04-09T19:56:24.475199Z","shell.execute_reply.started":"2024-04-09T19:56:24.465922Z","shell.execute_reply":"2024-04-09T19:56:24.474175Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Mamba model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel, MambaConfig, MambaForCausalLM\nimport torch\n\ntokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-2.8b-hf\")\n\nmodel = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-2.8b-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-04-11T21:55:56.071177Z","iopub.execute_input":"2024-04-11T21:55:56.072190Z","iopub.status.idle":"2024-04-11T21:57:21.697769Z","shell.execute_reply.started":"2024-04-11T21:55:56.072142Z","shell.execute_reply":"2024-04-11T21:57:21.696338Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/4.79k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"857f3763bfd44163acd0ae0a06a9022c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"447c8f3beef84c0b82b160de5c01f5c4"}},"metadata":{}},{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/843 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d5a3c3fd944b8ab32251848ee18b5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/50.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da3225d8012a4a29bc05342ef6176b2e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34e7e91a09f445fdb8649b1b17935e01"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00003.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43226c0374c043bfa7d2c695b6578935"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"08ec786c801d4ebdb02e884fe5f51a84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00003-of-00003.safetensors:   0%|          | 0.00/1.15G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99632217da6c4731b48392c411f3cdb0"}},"metadata":{}},{"name":"stderr","text":"The fast path is not available because on of `(selective_state_update, selective_scan_fn, causal_conv1d_fn, causal_conv1d_update, mamba_inner_fn)` is None. Falling back to the naive implementation. To install follow https://github.com/state-spaces/mamba/#installation and https://github.com/Dao-AILab/causal-conv1d\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cf3e2f588684de2b24d6bbc8f53352f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cc8096140b846e6b4c4983dfebbd919"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# text = \"russia - moscow germany - berlin france - paris japan - tokyo hungary - budapest spain - madrid italy - rome russia - \"\n# text = \"russia - moscow ; russia - moscow ; russia - moscow ; russia - moscow ; russia - moscow ; russia - \"\n# text = \"mom - maman; dad - papa; cat - chat; dog - chien; hello - bonjour; man - homme; woman - femme; god - dieu; sun - soleil; moon - lune; tree - arbre; red - rouge; blue - bleu; green - \"\ntext = \"boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - \"\ninput_ids = tokenizer.encode(text, return_tensors=\"pt\")\n\noutput = model.generate(input_ids, max_length=65, num_beams=5, no_repeat_ngram_size=2)\n\ngenerated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n\nprint(generated_text)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T21:59:51.324057Z","iopub.execute_input":"2024-04-11T21:59:51.324543Z","iopub.status.idle":"2024-04-11T22:00:53.290953Z","shell.execute_reply.started":"2024-04-11T21:59:51.324490Z","shell.execute_reply":"2024-04-11T22:00:53.289757Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - \nbad; happy - sad; healthy - sick; hot - cold; light - dark; love - -; -\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModel, MambaConfig, MambaForCausalLM\n# import torch\n\n# tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-2.8b-hf\")\n\n# model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-2.8b-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.500729Z","iopub.execute_input":"2024-04-09T19:56:24.501049Z","iopub.status.idle":"2024-04-09T19:56:24.510322Z","shell.execute_reply.started":"2024-04-09T19:56:24.501022Z","shell.execute_reply":"2024-04-09T19:56:24.509143Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# from transformers import GPT2Tokenizer, GPT2Model\n# tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n# model = GPT2Model.from_pretrained('gpt2')","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.514510Z","iopub.execute_input":"2024-04-09T19:56:24.515695Z","iopub.status.idle":"2024-04-09T19:56:24.521295Z","shell.execute_reply.started":"2024-04-09T19:56:24.515640Z","shell.execute_reply":"2024-04-09T19:56:24.520475Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"from transformers import GPT2Tokenizer, GPT2Model\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2-large')\nmodel = GPT2Model.from_pretrained('gpt2-large')\ntext = \"Replace me by any text you'd like.\"\nencoded_input = tokenizer(text, return_tensors='pt')\noutput = model(**encoded_input)","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:56:24.522701Z","iopub.execute_input":"2024-04-09T19:56:24.523280Z","iopub.status.idle":"2024-04-09T19:56:48.707961Z","shell.execute_reply.started":"2024-04-09T19:56:24.523249Z","shell.execute_reply":"2024-04-09T19:56:48.706935Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5c14023c3924fd886a3d6e132556b71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78e52263465145a989fda589fa533770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148cfb473ac140c1a927360d556d0bd8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e9c491414924a4aadf8616a092835c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e936ac12791473cbaf42ef083e150ad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a17a7a5c95cd451b910526a63efc5b36"}},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, set_seed\ngenerator = pipeline('text-generation', model='gpt2-large')\nset_seed(42)\n# text = \"russia - moscow germany - berlin france - paris japan - tokyo hungary - budapest spain - madrid italy - rome russia - \"\n# text = \"mom - maman; dad - papa; cat - chat; dog - chien; hello - bonjour; man - homme; woman - femme; god - dieu; sun - soleil; moon - lune; tree - arbre; red - rouge; blue - bleu; green - vert; black - \"\ntext = \"boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - \"\ngenerator(text, max_length=75, num_return_sequences=5)","metadata":{"execution":{"iopub.status.busy":"2024-04-11T22:02:08.944177Z","iopub.execute_input":"2024-04-11T22:02:08.945079Z","iopub.status.idle":"2024-04-11T22:02:49.526180Z","shell.execute_reply.started":"2024-04-11T22:02:08.945003Z","shell.execute_reply":"2024-04-11T22:02:49.524941Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'generated_text': 'boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - ___________ - perfect.\\n\\nDictionaries\\n\\nFrench - dictionnaire\\n\\nEnglish - standard English word list for computer programs and other texts\\n\\nEnglish - International'},\n {'generated_text': 'boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - \\xa0good; poor - \\xa0poverty; poorhouse - \\xa0poverty ward; slave - slave; street - \\xa0street; city - \\xa0city; poor'},\n {'generated_text': 'boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - ????; very - very ; come - go; get - get; go to - go to; have - have; have plenty - lots of; not - not; need -'},\n {'generated_text': 'boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - \\xa0Good; good-looking - pretty; good-luck - luck; goodie - a toy, object; goat - calf; great - extraordinary, great-grand; grandmother'},\n {'generated_text': \"boy - girl; buy - sell; expensive - cheap; child - adult; clean - dirty; cold - hot; discomfort - comfort; correct - wrong; create - destroy; good - ?????; help - help; goodbye - goodbye; good night - good night; goodbye - bye.\\n\\n\\nYou're looking good with her, but that's to be\"}]"},"metadata":{}}]},{"cell_type":"code","source":"# %pip install transformers==4.39","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:57:12.954756Z","iopub.execute_input":"2024-04-09T19:57:12.955100Z","iopub.status.idle":"2024-04-09T19:57:12.960877Z","shell.execute_reply.started":"2024-04-09T19:57:12.955069Z","shell.execute_reply":"2024-04-09T19:57:12.959066Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# from transformers import AutoTokenizer, AutoModel  # MambaConfig, MambaForCausalLM\n# import torch\n\n# tokenizer = AutoTokenizer.from_pretrained(\"state-spaces/mamba-130m-hf\")\n# # model = MambaForCausalLM.from_pretrained(\"state-spaces/mamba-130m-hf\")\n# model = AutoModel.from_pretrained(\"state-spaces/mamba-130m-hf\")","metadata":{"execution":{"iopub.status.busy":"2024-04-09T19:57:12.962640Z","iopub.execute_input":"2024-04-09T19:57:12.963310Z","iopub.status.idle":"2024-04-09T19:57:12.972768Z","shell.execute_reply.started":"2024-04-09T19:57:12.963276Z","shell.execute_reply":"2024-04-09T19:57:12.971724Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f73649f8-543c-4669-b1b7-fb86e6c3e7f0",
   "metadata": {},
   "source": [
    "# Mamba vs GPT2 evaluating\n",
    "\n",
    "We use https://github.com/state-spaces/mamba repository for Mamba model structure and https://github.com/EleutherAI/lm-evaluation-harness repo for evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de43e148",
   "metadata": {},
   "source": [
    "### Cloning and installing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78ddb4fd-18d3-4233-8260-fc0d4b35ead2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:14:10.795523Z",
     "iopub.status.busy": "2024-04-10T19:14:10.794700Z",
     "iopub.status.idle": "2024-04-10T19:14:12.412872Z",
     "shell.execute_reply": "2024-04-10T19:14:12.412013Z",
     "shell.execute_reply.started": "2024-04-10T19:14:10.795480Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'mamba'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/state-spaces/mamba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aa8edb-e025-41f1-96ae-eb233ddca032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install mamba-ssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a21af15c-6c9f-40ef-8625-7d595e15f200",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T18:02:45.816624Z",
     "iopub.status.busy": "2024-04-11T18:02:45.815552Z",
     "iopub.status.idle": "2024-04-11T18:02:45.833450Z",
     "shell.execute_reply": "2024-04-11T18:02:45.832380Z",
     "shell.execute_reply.started": "2024-04-11T18:02:45.816584Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/jupyter/datasphere/project/mamba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9acb9cd5-f3ec-4717-b5eb-c39939522e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:16:42.862011Z",
     "iopub.status.busy": "2024-04-10T19:16:42.861351Z",
     "iopub.status.idle": "2024-04-10T19:16:49.269098Z",
     "shell.execute_reply": "2024-04-10T19:16:49.268178Z",
     "shell.execute_reply.started": "2024-04-10T19:16:42.861976Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule path '3rdparty/lm-evaluation-harness': checked out 'a35206191acac1776761e737b66e0d04975d21b9'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Submodule '3rdparty/lm-evaluation-harness' (https://github.com/EleutherAI/lm-evaluation-harness/) registered for path '3rdparty/lm-evaluation-harness'\n",
      "Cloning into '/home/jupyter/work/resources/mamba/3rdparty/lm-evaluation-harness'...\n"
     ]
    }
   ],
   "source": [
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9786d570-42ee-47b7-88f1-904f682dffc6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:07:25.237074Z",
     "iopub.status.busy": "2024-04-10T18:07:25.236161Z",
     "iopub.status.idle": "2024-04-10T18:07:33.896368Z",
     "shell.execute_reply": "2024-04-10T18:07:33.895320Z",
     "shell.execute_reply.started": "2024-04-10T18:07:25.237038Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'lm-evaluation-harness'...\n",
      "Updating files: 100% (2442/2442), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone -b big-refactor https://github.com/EleutherAI/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658760b1-120e-4266-999d-3d829f5d9bdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install -e 3rdparty/lm-evaluation-harness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f760d575-1af9-424c-af54-90f65175d2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:20:56.468231Z",
     "iopub.status.busy": "2024-04-10T19:20:56.467511Z",
     "iopub.status.idle": "2024-04-10T19:21:05.265112Z",
     "shell.execute_reply": "2024-04-10T19:21:05.264300Z",
     "shell.execute_reply.started": "2024-04-10T19:20:56.468186Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q git+https://github.com/bigscience-workshop/promptsource.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e704397-0579-400a-a075-104d3c84f68d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:29:03.596849Z",
     "iopub.status.busy": "2024-04-10T19:29:03.595999Z",
     "iopub.status.idle": "2024-04-10T19:29:17.342357Z",
     "shell.execute_reply": "2024-04-10T19:29:17.341529Z",
     "shell.execute_reply.started": "2024-04-10T19:29:03.596799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install causal-conv1d>=1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99c5352d-726d-4ea5-87d3-650733f80831",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T18:19:37.391689Z",
     "iopub.status.busy": "2024-04-10T18:19:37.390779Z",
     "iopub.status.idle": "2024-04-10T18:20:09.086586Z",
     "shell.execute_reply": "2024-04-10T18:20:09.085242Z",
     "shell.execute_reply.started": "2024-04-10T18:19:37.391649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script transformers-cli is installed in '/home/jupyter/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install -q transformers==4.39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0b128-2641-4a3d-98e7-87c2f15f129d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "directory = '/home/jupyter/datasphere/project/mamba/'\n",
    "\n",
    "for subdir, dirs, files in os.walk(directory):\n",
    "    sys.path.append(subdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3583af56",
   "metadata": {},
   "source": [
    "### Evaluating\n",
    "\n",
    "We test models such tasks as `lambada_openai,piqa,arc_easy,arc_challenge,winogrande`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d65de5a-dffa-49fc-9faa-51d2a646bd38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T19:51:01.089035Z",
     "iopub.status.busy": "2024-04-10T19:51:01.088193Z",
     "iopub.status.idle": "2024-04-10T19:55:37.346681Z",
     "shell.execute_reply": "2024-04-10T19:55:37.345890Z",
     "shell.execute_reply.started": "2024-04-10T19:51:01.088993Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n",
      "hf (pretrained=state-spaces/mamba-130m-hf), limit: None, num_fewshot: None, batch_size: 8\n",
      "|    Tasks     |Version|Filter|  Metric  | Value |   |Stderr|\n",
      "|--------------|-------|------|----------|------:|---|-----:|\n",
      "|arc_challenge |Yaml   |none  |acc       | 0.1971|±  |0.0116|\n",
      "|              |       |none  |acc_norm  | 0.2423|±  |0.0125|\n",
      "|arc_easy      |Yaml   |none  |acc       | 0.4798|±  |0.0103|\n",
      "|              |       |none  |acc_norm  | 0.4192|±  |0.0101|\n",
      "|lambada_openai|Yaml   |none  |perplexity|16.0659|±  |0.5098|\n",
      "|              |       |none  |acc       | 0.4425|±  |0.0069|\n",
      "|piqa          |Yaml   |none  |acc       | 0.6447|±  |0.0112|\n",
      "|              |       |none  |acc_norm  | 0.6322|±  |0.0113|\n",
      "|winogrande    |Yaml   |none  |acc       | 0.5209|±  |0.0140|\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-04-10:19:51:04,977 INFO     [utils.py:160] NumExpr defaulting to 4 threads.\n",
      "2024-04-10:19:51:05,230 INFO     [config.py:58] PyTorch version 2.0.1+cu118 available.\n",
      "2024-04-10:19:51:05,231 INFO     [config.py:95] TensorFlow version 2.11.0 available.\n",
      "2024-04-10:19:51:05,232 INFO     [config.py:108] JAX version 0.4.13 available.\n",
      "2024-04-10 19:51:07.333198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-10 19:51:07.333316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-10 19:51:07.333332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-10:19:51:16,618 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for gsmk boolq, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-10:19:51:16,620 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for EleutherAI/asdiv, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-10:19:51:19,334 INFO     [__main__.py:184] Selected Tasks: ['arc_challenge', 'arc_easy', 'lambada_openai', 'piqa', 'winogrande']\n",
      "2024-04-10:19:51:19,385 INFO     [huggingface.py:118] Using device 'cuda:0'\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-04-10:19:51:45,709 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-10:19:51:45,709 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "Downloading data: 100%|██████████| 2.66M/2.66M [00:00<00:00, 3.85MB/s]\n",
      "Downloading data: 100%|██████████| 502k/502k [00:00<00:00, 1.08MB/s]\n",
      "Downloading data: 100%|██████████| 301k/301k [00:00<00:00, 704kB/s]\n",
      "Generating train split: 100%|██████████| 16113/16113 [00:00<00:00, 406151.64 examples/s]\n",
      "Generating test split: 100%|██████████| 3084/3084 [00:00<00:00, 336058.65 examples/s]\n",
      "Generating validation split: 100%|██████████| 1838/1838 [00:00<00:00, 281006.44 examples/s]\n",
      "Downloading data: 100%|██████████| 2.06M/2.06M [00:00<00:00, 7.23MB/s]\n",
      "Downloading data: 100%|██████████| 118k/118k [00:00<00:00, 358kB/s]\n",
      "Downloading data: 100%|██████████| 85.9k/85.9k [00:00<00:00, 541kB/s]\n",
      "Generating train split: 100%|██████████| 40398/40398 [00:00<00:00, 840300.20 examples/s]\n",
      "Generating test split: 100%|██████████| 1767/1767 [00:00<00:00, 333813.85 examples/s]\n",
      "Generating validation split: 100%|██████████| 1267/1267 [00:00<00:00, 268081.68 examples/s]\n",
      "2024-04-10:19:52:01,342 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:19:52:02,402 INFO     [evaluator.py:256] Task: arc_challenge; number of requests on this rank: 4687\n",
      "2024-04-10:19:52:02,404 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:19:52:04,545 INFO     [evaluator.py:256] Task: arc_easy; number of requests on this rank: 9501\n",
      "2024-04-10:19:52:04,548 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:19:52:13,312 INFO     [evaluator.py:256] Task: lambada_openai; number of requests on this rank: 5153\n",
      "2024-04-10:19:52:13,313 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:19:52:14,989 INFO     [evaluator.py:256] Task: piqa; number of requests on this rank: 3676\n",
      "2024-04-10:19:52:14,990 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:19:52:15,054 INFO     [evaluator.py:256] Task: winogrande; number of requests on this rank: 2534\n",
      "2024-04-10:19:52:15,055 INFO     [evaluator.py:288] Running loglikelihood requests\n",
      "100%|██████████| 25551/25551 [02:32<00:00, 167.84it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 evals/lm_harness_eval.py \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=state-spaces/mamba-130m-hf  --tasks lambada_openai,piqa,arc_easy,arc_challenge,winogrande \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9b0ac1d-83a2-47a6-99bf-17639be95251",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-10T20:04:33.123673Z",
     "iopub.status.busy": "2024-04-10T20:04:33.122813Z",
     "iopub.status.idle": "2024-04-10T20:08:20.674107Z",
     "shell.execute_reply": "2024-04-10T20:08:20.673288Z",
     "shell.execute_reply.started": "2024-04-10T20:04:33.123627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n",
      "hf (pretrained=openai-community/gpt2), limit: None, num_fewshot: None, batch_size: 8\n",
      "|    Tasks     |Version|Filter|  Metric  | Value |   |Stderr|\n",
      "|--------------|-------|------|----------|------:|---|-----:|\n",
      "|arc_challenge |Yaml   |none  |acc       | 0.1903|±  |0.0115|\n",
      "|              |       |none  |acc_norm  | 0.2270|±  |0.0122|\n",
      "|arc_easy      |Yaml   |none  |acc       | 0.4381|±  |0.0102|\n",
      "|              |       |none  |acc_norm  | 0.3948|±  |0.0100|\n",
      "|lambada_openai|Yaml   |none  |perplexity|40.0554|±  |1.4787|\n",
      "|              |       |none  |acc       | 0.3256|±  |0.0065|\n",
      "|piqa          |Yaml   |none  |acc       | 0.6289|±  |0.0113|\n",
      "|              |       |none  |acc_norm  | 0.6251|±  |0.0113|\n",
      "|winogrande    |Yaml   |none  |acc       | 0.5162|±  |0.0140|\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-04-10:20:04:36,584 INFO     [utils.py:160] NumExpr defaulting to 4 threads.\n",
      "2024-04-10:20:04:36,883 INFO     [config.py:58] PyTorch version 2.0.1+cu118 available.\n",
      "2024-04-10:20:04:36,883 INFO     [config.py:95] TensorFlow version 2.11.0 available.\n",
      "2024-04-10:20:04:36,884 INFO     [config.py:108] JAX version 0.4.13 available.\n",
      "2024-04-10 20:04:38.968581: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-10 20:04:38.968692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-10 20:04:38.968710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-10:20:04:48,091 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for gsmk boolq, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-10:20:04:48,093 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for EleutherAI/asdiv, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-10:20:04:50,801 INFO     [__main__.py:184] Selected Tasks: ['arc_challenge', 'arc_easy', 'lambada_openai', 'piqa', 'winogrande']\n",
      "2024-04-10:20:04:50,854 INFO     [huggingface.py:118] Using device 'cuda:0'\n",
      "2024-04-10:20:05:38,265 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-10:20:05:38,266 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-10:20:05:47,298 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:20:05:48,373 INFO     [evaluator.py:256] Task: arc_challenge; number of requests on this rank: 4687\n",
      "2024-04-10:20:05:48,374 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:20:05:50,513 INFO     [evaluator.py:256] Task: arc_easy; number of requests on this rank: 9501\n",
      "2024-04-10:20:05:50,516 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:20:05:59,289 INFO     [evaluator.py:256] Task: lambada_openai; number of requests on this rank: 5153\n",
      "2024-04-10:20:05:59,290 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:20:06:00,941 INFO     [evaluator.py:256] Task: piqa; number of requests on this rank: 3676\n",
      "2024-04-10:20:06:00,943 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-10:20:06:01,004 INFO     [evaluator.py:256] Task: winogrande; number of requests on this rank: 2534\n",
      "2024-04-10:20:06:01,005 INFO     [evaluator.py:288] Running loglikelihood requests\n",
      "100%|██████████| 25551/25551 [01:30<00:00, 282.83it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.57it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 evals/lm_harness_eval.py \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=openai-community/gpt2  --tasks lambada_openai,piqa,arc_easy,arc_challenge,winogrande \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96c34376-37fd-4f8c-a1a7-9807feb2c28a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T18:02:55.469682Z",
     "iopub.status.busy": "2024-04-11T18:02:55.468868Z",
     "iopub.status.idle": "2024-04-11T18:16:38.620606Z",
     "shell.execute_reply": "2024-04-11T18:16:38.619508Z",
     "shell.execute_reply.started": "2024-04-11T18:02:55.469637Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n",
      "hf (pretrained=openai-community/gpt2-xl), limit: None, num_fewshot: None, batch_size: 8\n",
      "|    Tasks     |Version|Filter|  Metric  | Value |   |Stderr|\n",
      "|--------------|-------|------|----------|------:|---|-----:|\n",
      "|arc_challenge |Yaml   |none  |acc       | 0.2500|±  |0.0127|\n",
      "|              |       |none  |acc_norm  | 0.2850|±  |0.0132|\n",
      "|arc_easy      |Yaml   |none  |acc       | 0.5829|±  |0.0101|\n",
      "|              |       |none  |acc_norm  | 0.5105|±  |0.0103|\n",
      "|lambada_openai|Yaml   |none  |perplexity|10.6341|±  |0.3292|\n",
      "|              |       |none  |acc       | 0.5121|±  |0.0070|\n",
      "|piqa          |Yaml   |none  |acc       | 0.7084|±  |0.0106|\n",
      "|              |       |none  |acc_norm  | 0.7051|±  |0.0106|\n",
      "|winogrande    |Yaml   |none  |acc       | 0.5833|±  |0.0139|\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-04-11:18:03:12,813 INFO     [utils.py:160] NumExpr defaulting to 8 threads.\n",
      "2024-04-11:18:03:13,213 INFO     [config.py:58] PyTorch version 2.0.1+cu118 available.\n",
      "2024-04-11:18:03:13,214 INFO     [config.py:95] TensorFlow version 2.11.0 available.\n",
      "2024-04-11:18:03:13,215 INFO     [config.py:108] JAX version 0.4.13 available.\n",
      "2024-04-11 18:03:24.998409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-11 18:03:24.999100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-11 18:03:24.999132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Downloading builder script: 100%|██████████| 5.67k/5.67k [00:00<00:00, 3.72MB/s]\n",
      "2024-04-11:18:03:46,836 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for gsmk boolq, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-11:18:03:46,840 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for EleutherAI/asdiv, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-11:18:03:51,827 INFO     [__main__.py:184] Selected Tasks: ['arc_challenge', 'arc_easy', 'lambada_openai', 'piqa', 'winogrande']\n",
      "2024-04-11:18:03:52,003 INFO     [huggingface.py:118] Using device 'cuda:0'\n",
      "2024-04-11:18:09:01,151 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-11:18:09:01,151 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-11:18:09:11,047 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:09:12,637 INFO     [evaluator.py:256] Task: arc_challenge; number of requests on this rank: 4687\n",
      "2024-04-11:18:09:12,639 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:09:15,864 INFO     [evaluator.py:256] Task: arc_easy; number of requests on this rank: 9501\n",
      "2024-04-11:18:09:15,867 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:09:28,359 INFO     [evaluator.py:256] Task: lambada_openai; number of requests on this rank: 5153\n",
      "2024-04-11:18:09:28,361 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:09:30,881 INFO     [evaluator.py:256] Task: piqa; number of requests on this rank: 3676\n",
      "2024-04-11:18:09:30,882 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:09:30,983 INFO     [evaluator.py:256] Task: winogrande; number of requests on this rank: 2534\n",
      "2024-04-11:18:09:30,984 INFO     [evaluator.py:288] Running loglikelihood requests\n",
      "100%|██████████| 25551/25551 [06:12<00:00, 68.68it/s] \n",
      "100%|██████████| 100/100 [00:21<00:00,  4.55it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 evals/lm_harness_eval.py \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=openai-community/gpt2-xl  --tasks lambada_openai,piqa,arc_easy,arc_challenge,winogrande \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65080c14-c93e-494a-b817-586c7131e02b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-11T18:27:26.570591Z",
     "iopub.status.busy": "2024-04-11T18:27:26.569458Z",
     "iopub.status.idle": "2024-04-11T18:40:46.303183Z",
     "shell.execute_reply": "2024-04-11T18:40:46.301927Z",
     "shell.execute_reply.started": "2024-04-11T18:27:26.570544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bootstrapping for stddev: perplexity\n",
      "hf (pretrained=state-spaces/mamba-1.4b-hf), limit: None, num_fewshot: None, batch_size: 8\n",
      "|    Tasks     |Version|Filter|  Metric  |Value |   |Stderr|\n",
      "|--------------|-------|------|----------|-----:|---|-----:|\n",
      "|arc_challenge |Yaml   |none  |acc       |0.2978|±  |0.0134|\n",
      "|              |       |none  |acc_norm  |0.3294|±  |0.0137|\n",
      "|arc_easy      |Yaml   |none  |acc       |0.6553|±  |0.0098|\n",
      "|              |       |none  |acc_norm  |0.6120|±  |0.0100|\n",
      "|lambada_openai|Yaml   |none  |perplexity|5.0425|±  |0.1206|\n",
      "|              |       |none  |acc       |0.6495|±  |0.0066|\n",
      "|piqa          |Yaml   |none  |acc       |0.7416|±  |0.0102|\n",
      "|              |       |none  |acc_norm  |0.7388|±  |0.0102|\n",
      "|winogrande    |Yaml   |none  |acc       |0.6140|±  |0.0137|\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/.local/lib/python3.10/site-packages/transformers/utils/hub.py:124: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n",
      "2024-04-11:18:27:31,820 INFO     [utils.py:160] NumExpr defaulting to 8 threads.\n",
      "2024-04-11:18:27:32,161 INFO     [config.py:58] PyTorch version 2.0.1+cu118 available.\n",
      "2024-04-11:18:27:32,162 INFO     [config.py:95] TensorFlow version 2.11.0 available.\n",
      "2024-04-11:18:27:32,164 INFO     [config.py:108] JAX version 0.4.13 available.\n",
      "2024-04-11 18:27:35.244140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-11 18:27:35.244311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/cuda/lib64:/usr/local/cuda/lib64\n",
      "2024-04-11 18:27:35.244335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2024-04-11:18:27:49,055 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for gsmk boolq, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-11:18:27:49,058 WARNING  [templates.py:592] Tried instantiating `DatasetTemplates` for EleutherAI/asdiv, but no prompts found. Please ignore this warning if you are creating new prompts for this dataset.\n",
      "2024-04-11:18:27:53,197 INFO     [__main__.py:184] Selected Tasks: ['arc_challenge', 'arc_easy', 'lambada_openai', 'piqa', 'winogrande']\n",
      "2024-04-11:18:27:53,287 INFO     [huggingface.py:118] Using device 'cuda:0'\n",
      "Downloading shards: 100%|██████████| 2/2 [02:20<00:00, 70.28s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.23s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "2024-04-11:18:32:41,839 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-11:18:32:41,839 WARNING  [task.py:303] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.\n",
      "2024-04-11:18:32:51,946 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:32:53,597 INFO     [evaluator.py:256] Task: arc_challenge; number of requests on this rank: 4687\n",
      "2024-04-11:18:32:53,599 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:32:56,909 INFO     [evaluator.py:256] Task: arc_easy; number of requests on this rank: 9501\n",
      "2024-04-11:18:32:56,913 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:33:09,734 INFO     [evaluator.py:256] Task: lambada_openai; number of requests on this rank: 5153\n",
      "2024-04-11:18:33:09,736 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:33:12,322 INFO     [evaluator.py:256] Task: piqa; number of requests on this rank: 3676\n",
      "2024-04-11:18:33:12,324 INFO     [task.py:358] Building contexts for task on rank 0...\n",
      "2024-04-11:18:33:12,433 INFO     [evaluator.py:256] Task: winogrande; number of requests on this rank: 2534\n",
      "2024-04-11:18:33:12,434 INFO     [evaluator.py:288] Running loglikelihood requests\n",
      "100%|██████████| 25551/25551 [06:38<00:00, 64.06it/s] \n",
      "100%|██████████| 100/100 [00:22<00:00,  4.52it/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 evals/lm_harness_eval.py \\\n",
    "    --model hf \\\n",
    "    --model_args pretrained=state-spaces/mamba-1.4b-hf  --tasks lambada_openai,piqa,arc_easy,arc_challenge,winogrande \\\n",
    "    --device cuda:0 \\\n",
    "    --batch_size 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8879755-5d24-4ff7-b53d-064ad98e6628",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
